Imagined visual representations as multimodal embeddings  
[TOC]
# 梳理
综述性文章，认真阅读

## Abstract
1. 我们所在的世界是多模态的：看到的物体，听见的声音，触碰的感觉，闻见的气味，品尝到的味道。模态modality指某事发生或体验的方式。一个重要的研究方向就是多模态，当其中涉及到多个上述的模态时。

2. 多模态是一个日益重要且充满活力的多学科领域。

3. 不同于以往的early fusion和late fusion等分类，本文将多模态分类为：
     - 表示representation
     - 翻译translation
     - 对齐alignment
     - 融合fusion
     - 协同学习co-learning.

# 1 INTRODUCTION 
4. 主要集中在三个模态上：语言language，视觉visual，声音vocal.

5. 为了让AI在理解身边的世界，需要让它们有能力解释和推理多模态信息。*多模态机器学习*目的是构建模型来处理process和关联relate多个模态的信息。早期的音频-视觉演讲识别到目前火热的语言-视觉模型，多模态学习是一个蒸蒸日上的跨领域学科，拥有着非凡的潜力。

6. 数据的异构性heterogeneity为多模态的研究带来了挑战。从多模态中学习为 捕捉模态数据间的关联 和 机器深入理解自然现象 带来了可能。

7. 五种挑战：
> 1. 表示 representation
> 如何利用多模态数据的互补性complementarity和冗余性redundancy来表示和归纳多模态数据？
> 多模态数据的异构性为这种表示带来了挑战。
>
> 2. 翻译 translation
> 如何将一个模态的数据翻译到另一个模态？
> 难点：异构性 + 模态和模态之间的关联通常是开放性的open-ended或者主观的subjective. 如一张图片可以有许多种正确描述。
>
> 3. 对齐 alignment
> 识别两个及以上的模态元素间的直接联系。
> 需要度量不同模态之间的相似性，处理可能的长范围依赖和歧义。
>
> 4. 融合 fusion
>
>   链接两个或以上的模态来进行预测。
>   来自不同模态的信息具有不同的预测能力和噪声拓扑，并且会有模态数据缺失的情况。
>
> 5. 合作学习 co-learning
> 迁移学习：模态的表示和预测模型的迁移。从一个模态中学习到的知识怎样帮助用另一个模态训练的模型。
> 某个模态的数据有限时。

# 2 APPLICATIONS: A HISTORICAL PERSPECTIVE
8. 介绍多模态应用的历史，从音频-视觉演讲内容识别到最近火热的语言-视觉应用。

## 音频-视频语音识别 Audio-Visual Speech Recognition (AVSR)
 - 早期的多模态应用是音频-视觉演讲内容识别AVSR，当时的许多模型都是基于了HMM的扩展。
 - 当时的实验结果表明，视觉信息加入的主要优势是在数据有噪声时(信噪比低时)也能学习到鲁棒的表示。换句话说，获取到的模态间的关联是补充的supplementary,而非互补的complementary.多模态数据提升了健壮性而没有提升效果。

## 多模态内容索引与检索 Multimodal Content Indexing and Retrieval
 - 互联网的发展使得多模态数据数量显著增加。
 - 以往的多媒体搜索都是基于关键词的，新的研究方向是直接搜索视觉信息和多模态内容。
 - 检索目标边界自动检测automatic shot-boundary detection和视频摘要video summarization

## 多模态人类行为理解 Understanding human multimodal behaviors during social interactions
 - 2000s出现的领域
     - 理解人类在社交活动中的多模态行为 
    Understanding of human multimodal behaivors during social interactions
    **两个重要的数据集** - the AMI Meeting Corpus, the SEMAINE corpus


 - 2010s早期，情感识别emotion recognition 和 情感计算affective computing 出现

## 语言和视觉模态 language and vision：media description
 - 代表性的应用: image caption
 - 媒体描述任务的挑战是如何评价获得的描述？
 - VQA

为了实现上述多模态应用，我们需要解决多模态机器学习中面临的一些技术问题。

# 3. 多模态表示 MULTIMODAL REPRESENTATIONS
**多模态表示的<u>评价标准</u>是什么？文章中是否有提及？**

- 表示学习(Representation Learning)研究将原始数据表示为算法或者模型可以处理的形式。

- 一般情况下。我们将原始数据表示成向量的形式，称为数据的表示(Representation)或特征(feature)。对于机器学习模型来说，构建好的特征是提高最终处理效果的重要因素。

- 如何用有意义的方式来表示数据是一个重要的研究问题，已成为许多模型的瓶颈。

- 挑战
    >- 如何组合异构的数据？
    >- 如何解决不同程度的噪音？
    >- 如何解决模态数据缺失的问题？

- 一个好的数据表示对机器学学模型来说很关键。 

>Begnio et al. 列出了好的表示需要具备的特点: 
>- 平滑的 smoothness, 
>- 时空连贯性 temporal and spatial coherence, 
>- 稀疏性 sparsity, 
>- 自然聚集 natural clustering amongst others
>
>Srivastava 和 Salakhutdinov 补充了多模态场景下需要的特点: 
>
>*   在表示空间中的相似性反映相关概念的相似性；
>*   特征应当能被简单地获得到——即使某些模态数据有缺失。
>*   有能力通过已有的其他模态数据来补充缺失模态的数据。

 - 过去的十年中，（单模态）表示学习已经从最初的**为特定应用手工设计特征**转变成**数据驱动**。直到最近，大多多模态表示方法还停留在简单地串联单模态表示向量，但现在已经在快速转变。
     - 尺度不变特征转换 (Scale-invariant feature transform, SIFT)到CNN
 - 多模态表示的两个类别：联合joint, 协同coordinated
> - *联合表示*组合单模态信号到相同的表示空间中。
> - *协同表示*分别单独处理单模态信号，但对它们强制执行某些约束以使它们达到我们所指的*协同空间*。 每个模态都有对应的映射函数，将其映射至一个协同多模态空间

## 3.1 联合表示 Joint Representation
1. 联合表示法多数用于多模态数据在训练和推断阶段都存在的任务上。
2. 最简单方法是串联单模态数据即 early fusion。
3. 更加先进的创建联合表示的方法有：神经网络、图模型、循环神经网络。

### 神经网络 Neural networks
 - 通常，神经网络是由一系列连续的块组成，这些块包含了内积和非线性的激活函数。
 - 为了使用神经网络表示数据，首先要将它训练在一个特定的任务上。一般利用最后或者倒数第二层的结果作为数据表示。
 - 利用神经网络构建多模态表示时，每个模态首先从各自的神经层开始，在一个隐含层中将这些模态映射到一个联合空间，随后，这个联合多模态表示会传递至多个多个隐含层或直接用来预测。
 - 这些模型可以端到端地训练，可以同时获得某个模态的表示，和进行某个特定的任务。
 - 由于神经网络需要大量标记数据，通常利用一个autoencoder在无监督数据上训练向量表示。
> - 神经网络的**主要优势**在于优秀的表现以及有能力用无监督的方式来预训练表示。当然，优秀的表现依赖大量训练数据。
> - **缺点**在于不能解决数据缺失，训练较为困难

### 概率图模型 Probabilistic graps hical models
 - 概率图模型通过隐含随机变量latent random variables构建向量表示。
 - 最流行的，基于概率图的表示方法是深度玻尔兹曼机deep Boltzmann machines (DBM), 组成成分为栈式受限的玻尔兹曼机stack restricted Boltzmann machines (RBM)。和神经网络类似，DBM的每一个层次都期望在一个更高层次的抽象上表示数据。
 - 概率图模型具有一定的生成能力。
> - 利用多模态DBMs进行多模态表示的**最大优点**是它们的生成能力generative nature.其次是它们可以从无监督数据中学习。
> - DBMs的**缺点**是训练它们需要高额的计算开销，并且需要利用近似变分训练方法approximate variational training methods.

### 序列表示 Sequential Representation
 - 之前讨论的表示方法都是针对固定长度的数据而言的，但是我们在实际运用中经常会遇到需要表示*可变长度序列*的方法，如句子，视频，音频流。
 - 循环神经网络在序列表示方面获得了较好的效果。
 - RNN表示不仅仅局限于单模态数据，已经有工作构建了一个利用RNN的多模态表示学习模型运用在AVSR,情感识别，人类行为分析上。

## 3.2 协同表示 Coordinated Representations
 - 联合表示的一个替代品是协同表示。协同表示并非将模态映射到一个联合空间中，而是分别学习每个模态的表示，通过一个限制来协同这些表示
  - 在表示之间强制相似 enforce similarity between representations
  - 在结果空间中强制更多的结构 enforce more structure on the resulting space

### 相似性模型 Similarity models
 - 最小化协同空间中各个模态的距离

### 结构化协同空间模型 structured coordinated space models
 - 在模态表示之间加上了更多的限制。
 - 根据具体应用确定限制条件。

#### 跨模态哈希 cross-modal hashing
 - 结构协同空间常常被运用在跨模态哈希上——压缩高维度的数据到紧凑的二元码(? compact binary codes)，要求相近的实体有着相近的二元码。利用这些二元码可以进行跨模态检索
  - 哈希对生成的多模态空间强制施加一些约束

#### 图像-语言顺序嵌入 order-embeddings of images and language
 - 目的是捕捉语言和图像之间的偏序关系，强制空间的等级制度。

#### 典型关联分析 caononical correlation analysis (CCA)
 - CCA计算一个线性映射来最大化两个随机变量之间的关联
 - CCA模型被运用在交叉领域检索和音频视频信号分析。
 - CCA, kernal CCA, Deep CCA 都是无监督学习并且只是优化了表示之间的关联。

 ## 讨论
 1. 有两种多模态表示的方法：联合表示和协同表示。
 2. 联合表示方法映射多模态数据到一个共同的空间中，适合在推断时也出现多模态数据时使用。联合表示法已经被广泛运用在AVSR，情感和手势识别任务中。
 3. 协同表示将多模态的数据映射到分开但协同的空间中，适合测试时中单个模态数据出现时使用，例如多模态检索和翻译。grounding，zero-shot learning. 
 4. 联合表示法已经被利用到两个或以上模态的情况中，而协同表示目前只被用于最多两个模态之中。

# 转化 TRANSLATION
 - 多模态机器学习的一个重要部分是将一个模态映射到另一个模态上去。任务是给予模态中的某一个实体，返回不同模态中的对应实体。例子：给出一张图像生成描述这张图像的句子，或是给定一段文本描述，生成一张图像来匹配它。
 - 多模态翻译是一个被长期研究的问题，早期的工作有语音合成，视觉语音生成speech synthesis, 视觉演讲生成visual speech generation, 视频描述video description, 跨模态检索cross-modal retrieval.
 - 目前，由于CV和NLP的迅速发展以及大型多模态数据集的出现，多模态翻译的热点发生了改变。例如视觉场景描述，即图片和视频标记问题。为了解决这个问题，我们不仅仅需要完全理解视觉场景并辨认出主要部分，还需要生成语法正确，全面但简洁的句子来描述它。
 - 可以将多模态翻译分为两类：**基于样例的模型**example-based和**生成模型**generative。其中，生成模型被认为是更有挑战性的，因为这些模型需要生成signals或者swquences of symbols. 这个任务对于每个模态来说都很困难，特别是生成时间-结构一致性的信息。所以很多早期的多模态翻译系统都依赖于基于样例的翻译。但是，深度学习已经有能力来生成图像，文本和声音了。

## 基于样例 example-based
 - 基于样例的算法受训练数据的限制——字典。
 - 有两种类型的算法：基于检索的模型 Retrieval-based models，和基于组合的模型combination-based
 - 基于样例的翻译方法缺点是 - 模型就是整个字典，让整个模型规模较大且推导缓慢。
 - 另一个问题是除非任务简单或者字典很大，不然全面且准确的原样例的解释不可能总存在于字典当中。


### 基于检索的模型 Retrieval models
 - 在字典中发现最相近的作为翻译结果。这种翻译可以在单模态空间或者中间语义空间完成。
>1. 单模态检索（没有看懂）
> - 单模态检索在源模态空间中找到字典中最相似的实体。
> - 单模态空间检索的好处是在检索式只要求单个模态数据的表示。
>2. 中间语义空间检索
> - 在语义空间检索的方法通常要由于单模态检索，因为语义空间是一个更具有意义的空间，它反映了多个模态的特征，并通常为检索做出了优化。
> - 而且，它支持双向翻译，这是单模态检索不能直接做到的。
>  - 但是这个方法需要手工构建或者学习到这样一个予以空间，依赖大量的训练dictionaries，成对样例的数据集。

### 基于组合的模型 Combination-based models
 - 基于组合的媒体描述方法的动机是图像的描述共享可被利用的简单的结构。
 - 略

## 生成方法
 - 生成方法构建了一个模型：给定一个单模态源实例，执行多模态翻译。
 - 生成方法的难度在于：
    1. 它需要同时理解源模态和生成目标序列target sequence或信号signal的能力。
    2. 由于可能正确答案的空间较大，生成方法的模型难以评估。
 - 主要讨论三个模态的生成：语言、视觉和声音。
     - 语言生成：图像视频描述生成。
     - 语音和声音生成
     - 照片般逼真的图像生成，处于研究的早期
 - 生成模型的三个类别：基于语法的、编码-解码器、连续生成模型

### 基于语法的生成模型 Grammar-based models
 - 依赖一个**预先定义好的语法规则**来生成一个特定模态的数据。从检测源模态的高阶概念开始，如图片中的实体和视频中的动作。这些发现被利用在一个预先定义好语法的生成模型中，来产生目标模态。
 - 例子：生成视频的描述文字

 - 基于语法的模型的**优点**是，由于利用了预先定义的模板和严格的御马，它们能够生成句法上syntactically, 或者火力上logically正确的目标实体
 - 缺点是它们只能生成公式化而缺乏创新的翻译。而且依赖于复杂的概念发现流程complex piplines for concept detection，每个概念都需要一个独立的模型和一个独立的训练集。

### 编码器-解码器模型 Encoder-decoder models
 - 先将源模态编码到一个向量空间中，然后利用一个解码器来生成目标模态的数据，所有的这些都在单个传递过程中进行。
 - 最初用在机器翻译当中，但是现在已被成功运用在图像标注，视频描述中。不仅仅是生成文本，它们还被用来生成图像、语音和声音。

 - 编码器-解码器模型的**第一步**是将源实体编码（利用多模态的方式）。
    >对于声音信号来说，通常用RNNs和DBNs进行编码。
    >文本句子常常用离散语义和RNNs的一些变种进行编码。
    >图像常常用CNN来进行编码，而视频常常利用手工构建的特征编码。
    >
    >虽然可以利用单模态表示来讲源模态编码，有研究指出协调空间表示会有一个更好的效果。

  - 解码步骤常常利用RNN或者LSTM，将编码表示当做出事隐含层。
    >利用RNN来进行翻译生成的一个问题是当生成一个长序列时，这些模型会倾向于忘记初始输入。
    >神经注意力模型部分缓解了这个问题。
  
  - 虽然基于神经网络的编码器=解码器模型取得了较好的效果，但是依然存在这一些问题。有研究指出，这种模型很可能知识记住了训练数据而非理解视觉场景并且成它。因为KNN模型的效果与其的效果十分地接近，并且训练这种模型需要大量的训练数据。

### 连续生成模型 Continuous generation models
 - 连续生成模型是为了序列翻译任务而提出的，它用一个在线的方式online manner来产出每一个时间步的结果。如文本到语音，语音到文本，视频到文本等等。
 - 一些技术：图模型、连续编码-解码器模型和其他分类、回归技术。
 - 连续生成的难点在于需要保证模态之间的时间一致性。
 - 早请，序列到序列翻译一般利用图模型graphical, 隐变量模型lantent variable model, 隐马尔科夫模型Hidden Markov models等等。
 - 目前多模态翻译主要采用连续的encoder-decoder模型，因为它们有能力表示和生成复杂的视觉和听觉信号。

## 模型评价与讨论
 - 多模态翻译的最大缺点在于难以评估（特别是语音合成与多媒体描述等任务）。许多答案都是正确的，但确定最好的一个是主观的
 - **多模态翻译的评价标准是一个值得研究的课题。**
 >1. 人类评估、用户偏好学习
 >
 >2. 自动化评估标准
 >BLEU ROUGE Meteor CIDEr
 >这类方法只有在相关翻译充足的情况下使用，通常是不现实的。
 >
 >3. 将检索作为评价图像标注的标准
 >不是让模型生成标注，而是给定一张图片，让模型排序已有的标注，检查正确的标注能否排在高位。
 - 评价方法的进步对多模态翻译的后续发展是至关重要的。
 - 好的评价方法不仅可以用来对比较两个模型的优劣，更是提供了一个更好的优化目标(better objective to optimize)。


# 对齐 ALIGNMENT
 - 我们定义多模态对齐为：从两个或以上的模态中寻找实例的子成分的联系(relationship)和对应(corresponding).
 - 例如：根据图像的标注寻找其对应的部分，根据电影片段寻找原著或剧本中的章节。

 - 两类多模态对齐：隐式(implict)与显式(explict).

## 显式对齐 Explicit alignment
 - 建模目标是对齐两个或以上模态中实例的子成分。
 - 显式对其中的一个重要部分是相似性度量(similarity metric).相似性可被人为地定义或是从数据中学习到。
 - 两种显式对齐的种类：无监督(unsupervised)和（弱）监督((weak) supervised)

### 无监督 Unsupervised
 - 无需任何直接的对齐标签
 - 模型假定某些限制：模态中建存在着时序关系，或是存在一个相似性度量。

#### [动态时间校正](https://en.wikipedia.org/wiki/Dynamic_time_warping) dynamic time warpping (DTW)
 - 利用动态规划思想对齐多视图时间序列(multi-view time series).
 - 计算两个序列之间的相似度并利用时间校正来寻找一个最优的匹配。
 - 预定义的相似性函数
 - 。。。 详细见[维基百科](https://en.wikipedia.org/wiki/Dynamic_time_warping) 

 - 文本到语音、视频。


 >- **典型相关分析** canonical-correlation analysis (CCA)
 >- CCA映射多模态数据到一个协调空间中。
 >- **DTW+CCA** 可以无监督地对齐模态数据，学习之间的映射关系。
 >- CCA based DTW无法对非线性关系建模
 >deep canonical time warping approach 解决非线性关系建模的问题

#### 图模型 graphical model （是概率图？？？）
 - 生成图模型generative graphical model对齐图像中的实体和说出的词汇、电影镜头、场景对应剧本。
 - a factored HMM 对应菜谱和厨艺视频。
  - ...

#### then
 - DTW和图形模型都允许对齐的限制：时间一致性，没有时间上的跳跃和单调的。
 - DTW允许联合学习相似性度量和对齐，基于图模型的方法构建时需要专家知识。

### 监督 Supervised
 - 有监督对齐模型依赖于带标签的对齐实体。它们通常用来训练**相似性度量？(similarity measures)**来对齐模态。

#### 非深度学习方法
 - canonical time warping + (weak) supervisory alignment data
 - CCA
 - a Gaussian mixture model
 - Markov random field

#### 深度学习方法 Deep learning based approaches

## 隐式对齐 Implicit alignment
 - 和显式对齐不同的是，隐式对齐一般用作其他任务的中间步骤。如语音识别、机器翻译、媒体描述和VQA.
 - 以上的任务不需要显式地对齐数据，但是在训练时需要隐含地对其数据。

### 早期工作：图模型 Graphical models
 - 需要人工手工构建模态之间的映射。

### 神经网络 Neural networks
 - 前述的Translation任务重需要利用神经网络(编码-解码器)。如果模型中没有隐式地对齐模态数据，那么编码器就需要放置许多参数来总结整张图片、句子或是视频。

#### Attention
 - 让解码器专注在源实体中某个子成分中。而非显式对齐中对齐所有成分。
 - 许多不同的注意力模型，分层、栈式、情节记忆注意力spisodic memory attention

#### Another
 - 点积相似度

## 讨论
 - 多模态对齐面临着一些问题：
     >- 数据集过少
     >- 相似性度量标准难以设计
     >- 存在多有可能的对齐方式

# 融合 FUSION
 - 多模态融合是多模态机器学习的最早的研究课题之一，之前的研究将其分类为早期融合法(early fusion)、晚期融合法(late fusion)、混合融合法(hybird fusion).
 - 在技术方面，多模态融合是将多种模态的信息结合，目标是预测一个任务的结果。
 - 多模态融合的三个优点：
     >- 从多个模态观测能够获得更加鲁棒的预测结果(eg. AVSR)；
     >- 能够捕捉到互补的信息；
     >- 当一个模态缺失后，多模态系统仍可以运行。
 - 现有的一些论文将所有的多模态算法都归类为多模态融合，这里的只将预测时用到多模态融合信息的方法称为多模态融合。
 - 在近期的工作中，多模态表示和融合的分界已经变得模糊，如深度神经网络中表示学习交叉着分类、回归任务。但是在图模型和基于核的模型中，其中的分界线是清晰的。
 - 两个主要分类：无模型的方法和基于模型的方法。

## 无模型方法 Model-agnostic approches
 - 无模型方法的一个优点是它们可以利用几乎所有的单模态分类器和回归器实现。

### 早期融合 Early fusion
 - 学习去挖掘每个模态低级特征(low level feature)的关联和交互.

### 晚期融合 Late fusion
 - 对不同的模态运用不同的模型——每种模型都有擅长处理的模态。
 - 在一个或多个以上模态数据丢失的情况下也可以预测。

 - 但是，晚期融合忽略了模态之间低级特征之间的交互性。


### 混合融合

## 基于模型的方法
 - 无模型方法的技术并不是为了多模态任务设计的。
 - 三种为多模态任务设计的方法：基于核的方法、图模型、神经网络。

### 多重核学习 Multiple kernel learning (MKL)
 - 为使用核方法的支持向量机的扩展，允许对不同的模态使用不同的核，体现了灵活性。
 - 核方法可以被看作是数据点之间的相似函数，在MKL中使用特定模态的核允许异构数据之间更好地融合。

 - 除了核函数选择的灵活性，MKL的一个有点事损失函数为凸函数，其能够使用标准的有花苞和全局优化方法来进行训练。
 - MKL的最主要缺点是测试阶段对训练数据的依赖，使得其推理较慢且耗费大量内存。

### 图模型 Graphical models
 - 主要分为两类：生成模型和判别模型。
 - 从隐马尔可夫到条件随机场。
 - 图模型可以方便地挖掘数据中的时空结构，并允许人类专家的知识加入到模型当中，并且通常是可解释的。

### 神经网络 Neural Networks
 - 尽管使用的模态、架构、优化技术会发生变化，在联合隐层融合信息的基本思想仍然相同。
 - 神经网络还用RNNs和LSTMs来融合时序多模态信息。

 - 优点
     >- 有能力从大量数据中学习；
     >- 允许端到端同时训练多模态表示和融合；
     >- 相比较非神经网络方法，神经网能够学习到复杂的决策边界。

- 缺点
    >- 不可解释；
    >- 需要大量的训练数据。

## 讨论
 - 许多方法被用来解决多模态融合，每一种方法都有各自的优劣。
 - 虽然神经网络目前成为了一个流行思路，但是图模型和多重核学习仍有一席之地，特别是训练数据少或模型可解释性很重要时。
 - 挑战
    >- 信号时序上不对齐
    >- 难以构建模型去挖掘补充不仅是互补的信息
    >- 每个模态也许会在不同的时间点表现出不同类型和不同级别的噪音


# 协同学习 CO-LEARNING
 - 通过从其他“资源丰富“的模态中挖掘知识来帮助“资源匮乏”的模态建模。
 - ”资源匮乏“指某个模态：缺少标记数据、输入多噪音、标记数据不可靠。
 - 将上述任务命名为”协同学习“，是因为”帮助者“模态只会在训练时使用，测试时不会用到它。
 - 基于训练的源数据，有三种协同学习的方法：
    >- 平行数据法(parallel data approach)：训练数据中，某个模态的观测数据可以直接关联到其他模态的观测数据。即由相同的实体观测到的多模态数据。
    >- 非平行数据法(non-parallel data approach)：不需要不同模态数据之间具有直接关联。这些方法通常使用类别和概念(categories and concepts)上的重叠(overlap)来实现协同学习。
    >- 混合数据法(hybird data setting)：实体和概念由第三个共享的模态（数据集）连接。

## 平行数据法 Parallel data
 - 两种算法更好地对多模态建模：协同训练co-training、迁移学习transfer learning

### 协同训练 Co-training
 - 在多模态任务中，当我们的标记样本数据不充足时，可以用协同训练来生成更多的有标记数据。
 - 基本思想是为每个模态构建弱分类器weak classifiers，来为无标记数据用标签互相引导(bootstrap each other with labels for the unlabeled data)。
 - 可以用来发现更多的训练数据，处理模态数据之间的不一致disagreement。
 - 但是，这种方法可能会生成有倾向的训练样本，使结果过拟合。（没有银弹）

### 迁移学习 Transfer learning
 - 利用多模态表示学习方法瑞深度玻尔兹曼机、多模态自编码器将信息从一个模态迁移到另一个模态上去。
 - 不仅生成多模态表示，还能形成更好的单模态表示(来表示多模态数据)，在测试时只用到单模态数据。

## 非平行数据法 Non-parallel data
 - 不需要模态之间有共享的实例，只需要有共享的共享的分类和概念。
 - 学习表示，更好的语义概念理解，甚至能进行未见物体识别(unseen object recognition)。

### 迁移学习 Transfer learning
 - 在非平行数据上的迁移学习也能够学习到更好的表示。它能将一个数据量充足/数据干净的模态迁移到数据量稀少/有噪声的模态。
 - 通常这类迁移学习由协同模态表示来实现。
 - 例如与word2vec特征协同训练来改善图像分类任务中的视觉表示。这样产生的视觉表示会使错误有意义。

### 建立概念基础？ Conceptual grounding
训练时加入其他模态的信息来得到语义概念表示？
 - 不只通过语言，也通过其他的一些模态如视觉，声音或是其未来学习语义semantic meaning和概念concepts.
 - 大多数概念学习的方法都是纯粹基于语言的，但是人类的意义表示不仅仅是我们语言的产物?(linguistic exposure)，还通过感觉经验和感知系统来建立。
 - 单纯地通过文本信息来学习语义可能不是最优的，需要促进视觉和声学信息的是用来建立语言表示linguistic representations.

 - 方法有寻找模态表示只见得共同隐含空间，或是各自学习单模态表示后进行串联。
 - 优点
    >- 一旦多模态表示构建完成，它就可以用在纯语言的任务当中。
    >- 这些表示对度量概念之间的相似性和相关性也同样有效——辨别两个词有怎样的语义和概念上的关联。
    >- 视觉、声音信息都可以用来构建概念。
 - 注意
    >- grounding不一定总是提高效果。
    >- 只有任务有关联才能提高效果。

### 零样本学习 Zero shot learning (ZSL)
 - 指在没有遇见任何相关样例的情况下识别一个概念。
 - ZSL对视觉物体分类任务很关键，因为为每个实体都提供训练数据是很昂贵的。


 - 两种ZSL的类型：
    >- 单模态
    >单模态ZSL识别对象的零部件或是属性，如通过颜色、大小和形状来预测一个没有见过的视觉类别，通过音位来识别一个从未听过的单词。
    >
    >- 多模态
    >多模态ZSL通过第二个模态的信息来识别多模态中的实体。
    >多模态ZSL面对非平行数据时会出现问题，因为模态之间类别重叠的部分是各不相同的。

## 混合数据 Hybird data
 - 在混合数据法中，两个非平行数据由一个共享的模态或者数据集链接。
 - 在Bridge Correlational Neural Network中，利用一个支点模态(a pivot modality)来学习非平行数据中的协调多模态表示。
 - 又如在机器翻译中的共享的支点语言

## 讨论
 - 多模态学习允许一个模态来影响另一个模态模型的训练过程，并挖掘模态之间的互补信息。
 - 协同学习是一个独立的任务

# 结论
 - 多模态机器学习的五个分类：representation, translation, fusion, alignment and co-learning
 - 某些任务如fusion已经被研究许久，在近期representation和translation较为热门。